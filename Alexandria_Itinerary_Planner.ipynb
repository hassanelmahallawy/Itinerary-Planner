{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15187e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd5f9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the places dataset\n",
    "places_df = pd.read_csv(\"places.csv\")\n",
    "# Load the plans dataset\n",
    "plans_df = pd.read_csv(\"plans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21f79310",
   "metadata": {},
   "outputs": [],
   "source": [
    "places_df['budget'] = places_df['budget'].apply(lambda x: x.split(','))\n",
    "budget_categories = ['low', 'medium', 'high']\n",
    "for category in budget_categories:\n",
    "    places_df[f'budget_{category}'] = places_df['budget'].apply(lambda x: 1 if category in x else 0)\n",
    "\n",
    "#drop budget\n",
    "places_df.drop('budget', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9959930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Parse the plans\n",
    "def extract_place_ids(plan_str):\n",
    "    day_plan = json.loads(plan_str)\n",
    "    all_places = []\n",
    "    for day_places in day_plan.values():\n",
    "        all_places.extend(day_places)\n",
    "    return all_places\n",
    "\n",
    "plans_df[\"place_ids\"] = plans_df[\"plan\"].apply(extract_place_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a76d40d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_days</th>\n",
       "      <th>plan</th>\n",
       "      <th>place_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{\"1\": [429, 545, 627, 500]}</td>\n",
       "      <td>[429, 545, 627, 500]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{\"1\": [505, 443, 574, 555]}</td>\n",
       "      <td>[505, 443, 574, 555]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{\"1\": [429, 627, 605], \"2\": [489, 500, 432]}</td>\n",
       "      <td>[429, 627, 605, 489, 500, 432]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_of_days                                          plan  \\\n",
       "0           1                   {\"1\": [429, 545, 627, 500]}   \n",
       "1           1                   {\"1\": [505, 443, 574, 555]}   \n",
       "2           2  {\"1\": [429, 627, 605], \"2\": [489, 500, 432]}   \n",
       "\n",
       "                        place_ids  \n",
       "0            [429, 545, 627, 500]  \n",
       "1            [505, 443, 574, 555]  \n",
       "2  [429, 627, 605, 489, 500, 432]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plans_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "277d580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create a lookup dict for place_id -> metadata\n",
    "places_df[\"place_id\"] = places_df[\"place_id\"].astype(int)\n",
    "places_meta = places_df.set_index(\"place_id\").to_dict(orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a90a9ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features_from_plan(place_ids, no_of_days):\n",
    "    places = [places_meta[pid] for pid in place_ids if pid in places_meta]\n",
    "    if not places:\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(places)\n",
    "    feature_dict = defaultdict(float)\n",
    "\n",
    "    # Categorical percentages for single-valued columns\n",
    "    for col in [\"category\", \"tourism_type\"]:\n",
    "        value_counts = df[col].value_counts(normalize=True)\n",
    "        for cat, pct in value_counts.items():\n",
    "            feature_dict[f\"{col}_{cat.lower().strip()}\"] = pct\n",
    "\n",
    "    # Handle multi-label \"budget\" column (e.g., \"medium, high\")\n",
    "    if \"budget\" in df.columns:\n",
    "        all_budgets = df[\"budget\"].dropna().str.split(\",\\s*\").explode()\n",
    "        budget_counts = all_budgets.value_counts(normalize=True)\n",
    "        for budget, pct in budget_counts.items():\n",
    "            feature_dict[f\"budget_{budget.lower().strip()}\"] = pct\n",
    "\n",
    "    # One-hot encode most common popularity category\n",
    "    if \"popularity_category\" in df.columns:\n",
    "        try:\n",
    "            most_common_pop = df[\"popularity_category\"].mode()[0]\n",
    "            feature_dict[f\"popularity_{most_common_pop.lower().strip()}\"] = 1\n",
    "        except IndexError:\n",
    "            pass\n",
    "\n",
    "    # # One-hot encode most common city_id\n",
    "    # if \"city_id\" in df.columns:\n",
    "    #     try:\n",
    "    #         most_common_city = df[\"city_id\"].mode()[0]\n",
    "    #         feature_dict[f\"city_id_{int(most_common_city)}\"] = 1\n",
    "    #     except IndexError:\n",
    "    #         pass\n",
    "    # One-hot encode \"with_who\" if available\n",
    "    if \"with_who\" in df.columns:\n",
    "        try:\n",
    "            most_common_with_who = df['with_who'].mode()[0]\n",
    "            parts = re.split(r\",\\s*|\\s+and\\s+\", most_common_with_who.lower().strip())\n",
    "            for part in parts:\n",
    "                clean_part = part.strip()\n",
    "                if clean_part:\n",
    "                    feature_dict[f\"with_who_{clean_part}\"] = 1\n",
    "        except IndexError:\n",
    "            pass  # no mode value found\n",
    "\n",
    "\n",
    "\n",
    "    # Add number of days\n",
    "    feature_dict[\"no_of_days\"] = no_of_days\n",
    "\n",
    "    return dict(feature_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51e88ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "targets = []\n",
    "\n",
    "for _, row in plans_df.iterrows():\n",
    "    f = extract_features_from_plan(row[\"place_ids\"], row[\"no_of_days\"])\n",
    "    if f:\n",
    "        features.append(f)\n",
    "        targets.append(row[\"place_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03269a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category_library': 0.25,\n",
       " 'category_museum': 0.25,\n",
       " 'category_theater': 0.25,\n",
       " 'category_garden': 0.25,\n",
       " 'tourism_type_cultural and historical attractions': 0.75,\n",
       " 'tourism_type_entertainment and modern attractions': 0.25,\n",
       " 'popularity_medium': 1,\n",
       " 'with_who_couple': 1,\n",
       " 'with_who_friends': 1,\n",
       " 'no_of_days': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57c96a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert features and targets\n",
    "X = pd.DataFrame(features).fillna(0)\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = pd.DataFrame(mlb.fit_transform(targets), columns=mlb.classes_)\n",
    "\n",
    "# Split and train XGBoost multi-label classifier\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ba541ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=&#x27;logloss&#x27;,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=&#x27;logloss&#x27;,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric='logloss',\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiOutputClassifier(XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "085b0bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "Y_pred = model.predict(X_test)\n",
    "report = classification_report(Y_test, Y_pred, target_names=[str(c) for c in Y.columns], zero_division=0, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e417149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85, 28),\n",
       " (85, 25),\n",
       " {'micro avg': {'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 1.0,\n",
       "   'support': 165},\n",
       "  'macro avg': {'precision': 0.96,\n",
       "   'recall': 0.96,\n",
       "   'f1-score': 0.96,\n",
       "   'support': 165},\n",
       "  'weighted avg': {'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 1.0,\n",
       "   'support': 165}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Return top-level evaluation summary\n",
    "summary_report = {\n",
    "    \"micro avg\": report[\"micro avg\"],\n",
    "    \"macro avg\": report[\"macro avg\"],\n",
    "    \"weighted avg\": report[\"weighted avg\"]\n",
    "}\n",
    "\n",
    "X.shape, Y.shape, summary_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3418cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_places_from_input(no_of_days, category_weights=None, tourism_type_weights=None, budget=None, popularity=None, with_who=None):\n",
    "    # Create a feature dict in the same way the training data was processed\n",
    "    feature_dict = {}\n",
    "\n",
    "    # 1. Categorical features for category and tourism type\n",
    "    if category_weights:\n",
    "        for cat, pct in category_weights.items():\n",
    "            feature_dict[f\"category_{cat.lower().strip().replace(' ', '_')}\"] = pct\n",
    "\n",
    "    if tourism_type_weights:\n",
    "        for ttype, pct in tourism_type_weights.items():\n",
    "            feature_dict[f\"tourism_type_{ttype.lower().strip().replace(' ', '_')}\"] = pct\n",
    "\n",
    "    # 2. Budget (multi-label, should be normalized like during training)\n",
    "    if budget:\n",
    "        feature_dict[f\"budget_{budget.lower().strip().replace(' ', '_')}\"] = 1\n",
    "\n",
    "    # 3. Popularity category (one-hot encoded)\n",
    "    if popularity:\n",
    "        feature_dict[f\"popularity_{popularity.lower().strip().replace(' ', '_')}\"] = 1\n",
    "\n",
    "\n",
    "    if with_who:\n",
    "        parts = re.split(r\",\\s*|\\s+and\\s+\", with_who.lower().strip())\n",
    "        for part in parts:\n",
    "            clean_part = part.strip()\n",
    "            if clean_part:\n",
    "                feature_dict[f\"with_who_{clean_part.replace(' ', '_')}\"] = 1\n",
    "    # 5. Number of days\n",
    "    feature_dict[\"no_of_days\"] = no_of_days\n",
    "\n",
    "    # Convert the feature dict into a DataFrame, using the same columns as the training data\n",
    "    x_input = pd.DataFrame([feature_dict], columns=X.columns).fillna(0)\n",
    "\n",
    "    # Make the prediction\n",
    "    y_pred = model.predict(x_input)\n",
    "\n",
    "    # Convert the multi-label output back to place IDs\n",
    "    predicted_place_ids = mlb.inverse_transform(y_pred)[0]  # Will give a list of place_ids\n",
    "\n",
    "    return predicted_place_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c808519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432, 487, 489, 500, 545, 620, 692)\n"
     ]
    }
   ],
   "source": [
    "x=predicted_places = predict_places_from_input(\n",
    "    no_of_days=3,\n",
    "    category_weights={\"zoo\": 1,\"shopping\":1,'garden':1},\n",
    "    tourism_type_weights={\"cultural\": 1, \"entertainment\": 1},\n",
    "    budget=\"medium\",\n",
    "    popularity=\"high\",\n",
    "    with_who=\"solo\"\n",
    ")\n",
    "\n",
    "print(predicted_places)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ae3e652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>Alexandria Montaza Gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>620</td>\n",
       "      <td>Alexandria National Museum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>692</td>\n",
       "      <td>Alexandria Zoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>545</td>\n",
       "      <td>Bibliotheca Alexandrina Antiquities Museum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>487</td>\n",
       "      <td>City Centre Alexandria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>489</td>\n",
       "      <td>Montaza Palace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>432</td>\n",
       "      <td>Royal Jewelry Museum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    place_id                                        name\n",
       "3        500                  Alexandria Montaza Gardens\n",
       "4        620                  Alexandria National Museum\n",
       "6        692                              Alexandria Zoo\n",
       "9        545  Bibliotheca Alexandrina Antiquities Museum\n",
       "10       487                      City Centre Alexandria\n",
       "17       489                              Montaza Palace\n",
       "23       432                        Royal Jewelry Museum"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = places_df[places_df[\"place_id\"].isin(x\n",
    ")]\n",
    "filtered = filtered[[\"place_id\",\"name\"]]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2906232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_days=3,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8588985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.15.0)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-genai) (4.9.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-genai) (2.18.1)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-genai) (2.10.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\users\\hassa\\appdata\\roaming\\python\\python311\\site-packages (from google-genai) (2.32.3)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-genai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hassa\\appdata\\roaming\\python\\python311\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (1.26.15)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9)\n",
      "Requirement already satisfied: certifi in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hassa\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hassa\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\hassa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f9708bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"no_of_days\": 3,\n",
      "    \"plan\": {\n",
      "        \"1\": [\n",
      "            487,\n",
      "            692,\n",
      "            620\n",
      "        ],\n",
      "        \"2\": [\n",
      "            500,\n",
      "            489\n",
      "        ],\n",
      "        \"3\": [\n",
      "            432,\n",
      "            545\n",
      "        ]\n",
      "    },\n",
      "    \"description\": \"Explore Alexandria's historical treasures and beautiful gardens in this amazing 3-day trip! üèõÔ∏è\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"------\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=\n",
    "    f\"\"\"\n",
    "    You're an expert tour guide. Design an itinerary planner, arranging the places optimally based on the provided places data.\n",
    "    Given the following places ({filtered} the result as JSON with a structure like:\n",
    "    {{\n",
    "        \"no_of_days\": {no_of_days}\n",
    "        \"plan\": {{\n",
    "            \"1\": [place_id1, place_id2],\n",
    "            \"2\": [place_id3, place_id4],\n",
    "            \"3\": [place_id5, place_id6]\n",
    "        \"description\": simple inspiring paragraph for the plan, 1 sentence + emoji\n",
    "        }}\n",
    "    }}\n",
    "    Ensure the output is optimal for a {no_of_days}-day itinerary (or other number of days as specified in the input), where each day includes a set of place_ids for the plan. Return the result as JSON.\n",
    "    Do not include any extra text, explanations, or formatting. Only return the JSON output.\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5650732a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlb.pkl']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model and other necessary components\n",
    "joblib.dump(model, \"model.pkl\")\n",
    "joblib.dump(X.columns.tolist(), \"feature_columns.pkl\")\n",
    "joblib.dump(mlb, \"mlb.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
